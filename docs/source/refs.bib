@Article{Gretton2012,
  Title                    = {A Kernel Two-sample Test},
  Author                   = {Gretton, A. and Borgwardt, K. M. and Rasch, M. J. and Sch\"{o}lkopf, B. and Smola, A.},
  Journal                  = {Journal of Machine Learning Research (JMLR)},
  Year                     = {2012},

  Month                    = mar,
  Pages                    = {723--773},
  Volume                   = {13},

  Acmid                    = {2188410},
  ISSN                     = {1532-4435},
  Issue_date               = {3/1/2012},
  Keywords                 = {hypothesis testing, integral probability metric, kernel methods, schema matching, two-sample test, uniform convergence bounds},
  Numpages                 = {51},
  Publisher                = {JMLR.org}
}
@Misc{UCI,
  Title                    = {{UCI} Machine Learning Repository},

  Author                   = {M. Lichman},
  Year                     = {2013},

  Institution              = {University of California, Irvine, School of Information and Computer Sciences},
  Url                      = {http://archive.ics.uci.edu/ml}
}
@article{Arenz2020,
  author  = {Oleg Arenz and Mingjun Zhong and Gerhard Neumann},
  title   = {Trust-Region Variational Inference with Gaussian Mixture Models},
  journal = {Journal of Machine Learning Research},
  year    = {2020},
  volume  = {21},
  number  = {163},
  pages   = {1-60},
  url     = {http://jmlr.org/papers/v21/19-524.html}
}

@InProceedings{Khan2018a,
  title = 	 {Fast and Scalable {B}ayesian Deep Learning by Weight-Perturbation in {A}dam},
  author =       {Khan, Mohammad and Nielsen, Didrik and Tangkaratt, Voot and Lin, Wu and Gal, Yarin and Srivastava, Akash},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2611--2620},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR}}
}
@InProceedings{Lin2020,
  title = 	 {Handling the Positive-Definite Constraint in the {B}ayesian Learning Rule},
  author =       {Lin, Wu and Schmidt, Mark and Khan, Mohammad Emtiyaz},
  booktitle = 	 {Proceedings of the 37th International Conference on Machine Learning},
  pages = 	 {6116--6126},
  year = 	 {2020},
  editor = 	 {III, Hal Daum√© and Singh, Aarti},
  volume = 	 {119},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {13--18 Jul},
  publisher =    {PMLR},
}
@InProceedings{Abdolmaleki2015,
  Title                    = {Model-Based Relative Entropy Stochastic Search},
  Author                   = {A. Abdolmaleki and R. Lioutikov and N. Lua and L. Paulo Reis and J. Peters and G. Neumann},
  Booktitle                = {Advances in Neural Information Processing Systems (NeurIPS)},
  Year                     = {2015},
  Pages                    = {153--154},

  Abstract                 = {Stochastic search algorithms are general black-box optimizers. Due to their ease of use and their generality, they have recently also gained a lot of attention in operations research, machine learning and policy search. Yet, these algorithms require a lot of evaluations of the objective, scale poorly with the problem dimension, are affected by highly noisy objective functions and may converge prematurely. To alleviate these problems, we introduce a new surrogate-based stochastic search approach. We learn simple, quadratic surrogate models of the objective function. As the quality of such a quadratic approximation is limited, we do not greedily exploit the learned models. The algorithm can be misled by an inaccurate optimum introduced by the surrogate. Instead, we use information theoretic constraints to bound the ?distance? between the new and old data distribution while maximizing the objective function. Additionally the new method is able to sustain the exploration of the search distribution to avoid premature convergence. We compare our method with state of art black-box optimization methods on standard uni-modal and multi-modal optimization functions, on simulated planar robot tasks and a complex robot ball throwing task. The proposed method considerably outperforms the existing approaches.},
  Journal                  = {GECCO 2016 Companion - Proceedings of the 2016 Genetic and Evolutionary Computation Conference}
}
@article{Pajarinen2019,
  author =		 "Pajarinen, J. and  Thai, H.L. and  Akrour, R. and  Peters, J. and  Neumann, G.",
  year =		 "2019",
  title =		 "Compatible natural gradient policy search",
  journal =		 "Machine Learning (MLJ)",
  key =			 "roboleap,skills4robots",
  publisher =		 "springer",
  number =		 "8",
  pages =		 "1443--1466",
}

@article{Peters2008,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}
@inproceedings{Sutton1999,
 author = {Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Solla and T. Leen and K. M\"{u}ller},
 pages = {},
 publisher = {MIT Press},
 title = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
 url = {https://proceedings.neurips.cc/paper/1999/file/464d828b85b0bed98e80ade0a5c43b0f-Paper.pdf},
 volume = {12},
 year = {1999}
}
@article{Lin2019Stein,
  title={Stein's Lemma for the Reparameterization Trick with Exponential Family Mixtures},
  author={Lin, Wu and Khan, Mohammad Emtiyaz and Schmidt, Mark},
  journal={arXiv preprint arXiv:1910.13398},
  year={2019}
}
@inproceedings{Lin2019,
  title={Fast and simple natural-gradient variational inference with mixture of exponential-family approximations},
  author={Lin, Wu and Khan, Mohammad Emtiyaz and Schmidt, Mark},
  booktitle={International Conference on Machine Learning},
  pages={3992--4002},
  year={2019},
  organization={PMLR}
}
@InProceedings{Arenz2018,
  title = 	 {Efficient Gradient-Free Variational Inference using Policy Search},
  author = 	 {Arenz, O. and Zhong, M. and Neumann, G.},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2018},
}
@article{
  Arenz2023,
  title={A Unified Perspective on Natural Gradient Variational Inference with Gaussian Mixture Models},
  author={Arenz, O. and Dahlinger, P. and Ye, Z. and Volpp, M. and Neumann, G.},
  journal={Transactions on Machine Learning Research},
  year={2023},
  url={https://openreview.net/forum?id=tLBjsX4tjs},
}